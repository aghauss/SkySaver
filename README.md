<div style="display: flex; align-items: center;">
    <img src="https://github.com/aghauss/SkySaver/assets/148491489/8c89cab7-c542-4ca5-8b43-6d2cf1c3b9f7" alt="Skysaver Logo" width="100" style="margin-right: 10px;">
    <h1>Skysaver</h1>
</div>


## Description

Skysaver is an application designed to help users optimize their flight costs by leveraging IP location switching. 

Skysaver consists of an end-user application where users can enter their desired journey and find out whether there is a potential to save money, how high that potential is in % and to which country they should relocate their IP to get the highest savings. The tool is based on a dataset that was generated by running multiple webscrawers identical queries through different IP-Location on a popular flight search service.

The repository contains all scripts to replicate the tool by rerunning the webscraper to generate a sufficient dataset and retrain the model. The applications is based on an ExtraTreeRegressor Model prediciting the potential saving in % and a ExtreTreaClassification Model prediciting the country with the highest saving potential.

<img width="1414" alt="image" src="https://github.com/aghauss/SkySaver/assets/148491489/b38fcf7e-c41a-409d-9472-23349c449d6a">


## Features

- Unique IP location-based flight cost optimization.
- Advanced web crawling to gather flight data from Google Flights across a wide range of countries.
- Structured data transformation into CSV format for analysis.
- A comprehensive data preprocessing pipeline to prepare the training dataset.
- Predictive modeling to inform users of potential savings through IP location switching.



## Getting Started

### Prerequisites

- Python 3.8 or newer
- List of residential proxies for the webscraper (most providers charge a fee per GB of traffic)

### Installation

1. Clone the repository to your local machine:
```bash
git clone https://yourrepositoryurl/Skysaver.git
cd Skysaver
```

2. Install the required Python packages:
```bash
   pip install -r requirements.txt
```

### Setup

In order to run the webscraper it is necessary to provide a JSON configuration file that contains the list of proxy servers to connect to. An exemplrary entry looks like this:

{"server": "pr.oxylabs.io:7777", "username": "aghss", "password": "DamnSon31er_", "country": "RD"}

Additionally it is necessary to provide the query JSON file, which contains the list of queries. One entry should contain the name of the deprature airport, the destination airport, the departure date and the destination date. As an example:

 {
        "departure": "DEN",
        "destination": "SFO",
        "departure_date": "28.03.2024",
        "return_date": "06.05.2024"
    },

Lastly, it is necessary to provide custom headers to the webscraper. Custom headers incorporate typically browser configuration of the country that the webscrapes is relocated to. A custom header should look like this:

"GB": {
      "Accept-Language": "en-GB,en;q=0.9",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
    },

## Usage

Follow the steps below to start leveraging Skysaver for your flight queries:

1. Navigate to the `src` directory:
```bash
cd src
```
2. Run the web crawler to collect flight data (Note: This step requires appropriate configurations for IP switching):
```bash
python 0_flight_query_executor.py --config your_config.json
```

3. Run the web crawler to collect flight data (Note: This step requires appropriate configurations for IP switching):
```bash
python 1_csv_converter.py 
```

3. Preprocess the collected data to prepare the training dataset:
```bash
python 2_data_preprocessor.py
```

4. Train the predictive model with the preprocessed data:
```bash
python 3_model_creator.py
```

5. (Optional) Test model accuracy with a test set:
```bash
python flight_query_executor.py --flight-query your_query.json
```

Replace `your_config.json`, `your_query.json`, and other placeholders with actual file names or arguments as per your setup and requirements.



## Technologies Used

- Python
- Playwright for Python (for asynchronous web scraping)
- PyCaret (for machine learning model creation and evaluation)
- Pandas (for data manipulation)
